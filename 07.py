# -*- coding: utf-8 -*-
"""07.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dqG1_7qsK82f5-UycjmboxJGFjTcGZHP
"""

import numpy as np
import matplotlib.pyplot as plt
import timeit

# defining the function to be interpolated
def f(x):
    return np.exp(x + x**2)

def Gauss(A, b):
#The number of equations in the system (the same as the length of the vector b)
    N=len(b)
#First, I have to find the index of the row with the largest absolute value in the i-th column of the matrix A (pivot row)
    for i in range(N):
        pivot_col=i
        pivot_val=abs(A[i, i])
        for j in range(i+1, N):
            if abs(A[j, i])>pivot_val:
                pivot_col=j
                pivot_val=abs(A[j, i])
        pivot_row=pivot_col
        #Then I should swap the i-th row with the pivot row in the matrix A and vector b
        #This is done to be sure that the pivot element (the element in the i-th column and i-th row) is nonzero
        if i!=pivot_row:
            A[[i,pivot_row]]=A[[pivot_row,i]]
            b[[i,pivot_row]]=b[[pivot_row,i]]
        #Then I need to compute a factor that is used to subtract a multiple of the i-th row from each subsequent row
        for j in range(i + 1, N): #Eliminating the i-th variable
            factor=A[j, i]/A[i, i]
            A[j, i+1:]=A[j, i+1:]-(A[j, i]/A[i, i])*A[i, i+1:]
            b[j]=b[j]-(A[j, i]/A[i, i])*b[i]
        #The matrix A and vector b have been transformed into an upper-triangular form.
    x=np.zeros(N)
#back-substitution to solve for the variables:
    for i in range(N-1,-1,-1):
        x[i]=(b[i]-np.dot(A[i,i+1:], x[i+1:]))/A[i, i]
#iterating over the rows of the matrix A in reverse order, starting from the last row
    return x

def cubic(x, y):
    n=len(x) #getting the number of data points
    h=x[1:]-x[:-1] #Calculating the intervals between adjacent x-values
    delta=(y[1:]-y[:-1])/h #calculating the slopes between adjacent y-values
    A=np.zeros((n, n)) #initializing the matrix A and vector b
    b=np.zeros(n)
    #set up the system of equations to solve for the second derivatives of the cubic spline
    for i in range(1, n - 1):
        A[i, i-1]=h[i-1]
        A[i, i]=2*(h[i-1]+h[i])
        A[i, i+1]=h[i]
        b[i]=3*(delta[i]-delta[i-1])
    A[0, 0]=1 #appling the natural cubic spline conditions
    A[n-1, n-1]=1
    c=Gauss(A, b) #solving the system of equations to get the second derivatives of the cubic spline
    #calculating the coefficients of each cubic segment of the spline
    a=y[:-1]
    b=delta-h*(2*c[:-1]+c[1:])/3
    d=(c[1:]-c[:-1])/(3*h)
    #defining a function to interpolate the spline at a given x-value t
    def f_interp(t):
      i=np.searchsorted(x, t) - 1 #finding the indices of the segments that contain each element of t
      i=np.maximum(i, 0) #handle any elements of t that are less than the smallest x-value
      i=np.minimum(i, n-2) #handle any elements of t that are greater than the largest x-value
      s=t-x[i] #interpolate using the cubic segment that contains each element of t
      return a[i]+b[i]*s+c[i]*s**2+d[i]*s**3
    return f_interp #returning the interpolation function

def linear_spline(xi, x, y):
    n=len(x) #number of data points
    if xi<=x[0]: #if xi is smaller than the smallest x-coordinate, return y[0]
        return y[0]
    elif xi>= x[-1]: #if xi is larger than the largest x-coordinate, return y[-1]
        return y[-1]
    else:
        for i in range(n-1):
            #if xi is between two consecutive x-coordinates, perform linear interpolation.
            if x[i]<=xi<=x[i+1]:
                # Calculating the slope of the line connecting the two data points.
                slope=(y[i+1]-y[i])/(x[i+1]-x[i])
                # estimating the value of the function at xi using the equation of a line.
                return y[i]+slope*(xi-x[i])

def rmsd(predicted, actual):
    # Calculating the squared difference between the predicted and actual values
    squared_error=(predicted-actual)**2
    # Calculating the mean squared error
    mse=np.mean(squared_error)
    # Calculating the root mean squared error
    rmsd=np.sqrt(mse)
    return rmsd

#defining the data points
x=np.array([0.25*i for i in range(9)])
x_plot=np.linspace(0, 2, 50)
y=f(x)
log_y = np.log(y)

#computing the time for compiling interpolating functions
start_time1 = timeit.default_timer()
f_interp = cubic(x, y)
y_cubic=f_interp(x_plot)
total_time1 = timeit.default_timer() - start_time1

start_time2 = timeit.default_timer()
y_linear=np.array([linear_spline(xi, x, y) for xi in x_plot])
total_time2 = timeit.default_timer() - start_time2

start_time3 = timeit.default_timer()
y_log_lin = np.exp([linear_spline(xi, x, log_y) for xi in x_plot])
total_time3 = timeit.default_timer() - start_time3

start_time4 = timeit.default_timer()
y_log_cube = np.exp([cubic(x, log_y)(xi) for xi in x_plot])
total_time4 = timeit.default_timer() - start_time4

y_true=f(x_plot)

#plot the interpolating functions and the original function
plt.plot(x_plot, y_cubic, label='Cubic Spline')
plt.plot(x_plot, y_linear, label='Linear Spline')
plt.plot(x_plot, y_log_cube, label="Log Cubic Spline")
plt.plot(x_plot, y_log_lin, label="Log Linear Spline")
#plt.plot(x_plot, y_true, label='True function')
plt.scatter(x, y, label='Data points')
#plt.yscale('log')
plt.legend()
plt.show()

div_cube=rmsd(y_cubic, y_true)
div_lin=rmsd(y_linear, y_true)
div_log_lin=rmsd(y_log_lin, y_true)
div_log_cube=rmsd(y_log_cube, y_true)

N_cubic=9**3
N_lin=9-1
cost_cubic=total_time1/N_cubic
cost_linear=total_time2/N_lin
cost_log_cub=total_time3/N_cubic
cost_log_lin=total_time4/N_lin

"""####Creating table with results"""

from tabulate import tabulate
table1 = [['Method', 'RMSD', 'Time', 'Cost'],
         ["Cubic", div_cube, total_time1, cost_cubic ],
         ["Linear", div_lin, total_time2, cost_linear],
         ["Log Cubic", div_log_cube, total_time3, cost_log_cub],
         ["Log Linear", div_log_lin, total_time4, cost_log_lin]]

"""###**Results**
It can be seen in the plot that all the methods visually are pretty accurate.
However, if we look at the Root Mean Squared Deviation error and Cost, it can be seen that methods significantly vary.
It can be clearly seen that the most efficient method with the least error is Log Cubic method.
"""

print(tabulate(table1, headers='firstrow'))

"""###**Conclusion**
In conclusion, this problem involved generating linear and cubic splines to interpolate between 9 data points of the given function. The interpolation was done both directly and after taking the logarithm of the function. It was found that logarithmic cubic spline interpolation was the most efficient method with the least error, indicating that it provided the best quantitative accuracy with the least computational cost.
"""
